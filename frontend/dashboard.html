<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Audio Cough Detection - Dashboard</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        :root{
            --bg: #ffffff; /* white background */
            --card: #fbfbff; /* soft card */
            --muted: #6b7280; /* gray */
            --accent: #7cc4d6; /* pastel teal */
            --accent-2: #ffd4d4; /* pastel pink */
            --accent-3: #f6e7ff; /* pastel lavender */
            --text: #0f1720;
            --surface: #ffffff;
            --shadow: 0 6px 18px rgba(15,23,32,0.06);
        }
        body{background:var(--bg);color:var(--text);font-family:Inter,system-ui,-apple-system,Arial,Helvetica,sans-serif;margin:0}
        .container{max-width:1200px;margin:18px auto;padding:18px}
        .site-header{display:flex;align-items:center;justify-content:space-between;gap:12px;padding:14px 0}
        .dashboard-grid{display:grid;grid-template-columns:280px 1fr 360px;gap:20px}
        .sidebar .profile-card{background:var(--card);padding:14px;border-radius:12px;box-shadow:var(--shadow)}
        .profile-header{display:flex;justify-content:space-between;align-items:center}
        .profile-header h3{margin:0;font-size:18px}
        .muted{color:var(--muted);margin:6px 0}
        .recipients-list{margin-top:12px}
        .recipient-card{background:linear-gradient(180deg, rgba(124,196,214,0.06), rgba(246,231,255,0.03));padding:12px;border-radius:12px;margin-bottom:10px;display:flex;justify-content:space-between;align-items:center;cursor:pointer;border:1px solid rgba(15,23,32,0.03)}
        .recipient-card.active{box-shadow:0 6px 18px rgba(124,196,214,0.12);border-color:rgba(124,196,214,0.25);transform:translateY(-2px)}
        .recipient-name{font-weight:800}
        .recipient-meta{color:var(--muted);font-size:13px}
        .recipient-actions button{background:transparent;border:1px solid rgba(15,23,32,0.06);padding:6px 10px;border-radius:8px;cursor:pointer}

        .mainpanel .panel{background:var(--surface);padding:18px;border-radius:12px;box-shadow:var(--shadow)}
        .panel-header{display:flex;justify-content:space-between;align-items:center}
        .monitor-controls{display:flex;align-items:center;gap:12px;margin-top:12px}
        .primary{background:var(--accent);color:var(--text);border:none;padding:10px 16px;border-radius:10px;font-weight:700;cursor:pointer}
        .status{color:var(--muted);font-weight:600}
        .monitor-body{display:grid;grid-template-columns:1fr 360px;gap:14px;margin-top:16px}
        .left{flex:1}
        .right{width:360px}
        .waveform{background:#fff9fb;padding:12px;border-radius:10px;border:1px solid rgba(15,23,32,0.04)}
        .recordings-list{display:flex;flex-direction:column;gap:8px}
        button{cursor:pointer}
        a.logout{color:var(--accent-2);text-decoration:none;font-weight:700}

        .panel-sub{margin-top:12px}
        .small{font-size:13px}
        .chip{display:inline-block;padding:6px 10px;border-radius:999px;background:var(--accent-3);border:1px solid rgba(15,23,32,0.03);font-weight:700}

        .history-list, .session-list{max-height:420px;overflow:auto;padding:8px;border-radius:8px;background:linear-gradient(180deg, rgba(11,18,32,0.02), rgba(11,18,32,0.01))}
        .header-card{background:var(--card);padding:12px;border-radius:12px;box-shadow:var(--shadow);display:flex;align-items:center;gap:12px}
        .caretaker-meta{display:flex;flex-direction:column}
        
        /* Logout button styles */
        .logout-btn{background:#ff6b6b;color:white;border:none;padding:8px 16px;border-radius:8px;font-weight:600;cursor:pointer;font-size:13px;margin-left:8px}
        .logout-btn:hover{background:#ff5252}
    </style>
</head>

<body>
    <div class="container">
        <header class="site-header">
            <div class="header-card">
                <div style="width:56px;height:56px;border-radius:8px;background:linear-gradient(180deg,var(--accent-3),var(--accent-2));display:flex;align-items:center;justify-content:center;font-weight:800;color:var(--text)">CT</div>
                <div class="caretaker-meta">
                    <div id="caretakerName">â€”</div>
                    <div class="muted small" id="caretakerEmail">&nbsp;</div>
                </div>
            </div>
            <div style="display:flex;gap:12px;align-items:center">
                <div id="headerActions" style="display:flex;gap:8px;align-items:center">
                    <button id="openProfileBtn" class="chip small">Profile</button>
                    <!-- ADDED LOGOUT BUTTON -->
                    <button id="logoutBtn" class="logout-btn">Logout</button>
                </div>
            </div>
        </header>

        <main class="dashboard-grid">
            <aside class="sidebar" aria-label="Recipients">
                <div class="profile-card">
                    <div style="display:flex;justify-content:space-between;align-items:center">
                        <h4 style="margin:0">Care Recipients</h4>
                        <input id="recipientSearch" placeholder="Search" style="padding:6px;border-radius:8px;border:1px solid rgba(15,23,32,0.04);font-size:13px" />
                    </div>
                    <div id="recipientsList" class="recipients-list" style="margin-top:12px;max-height:560px;overflow:auto">
                        <p class="muted">Loading recipientsâ€¦</p>
                    </div>
                </div>
            </aside>

            <section class="mainpanel" role="main">
                <div class="panel">
                    <div class="panel-header">
                        <h2 style="margin:0">Audio Monitoring</h2>
                        <div style="text-align:right">
                            <div id="welcomeMsg" class="muted">Loading...</div>
                            <div class="small muted">Selected: <strong id="selectedRecipient">All</strong></div>
                        </div>
                    </div>

                    <div class="monitor-controls" style="margin-top:12px">
                        <button id="startBtn" class="primary">Start Listening</button>
                        <div id="status" class="status" style="margin-left:12px">Status: Not listening</div>
                        <div style="margin-left:auto" class="small muted">Coughs: <strong id="coughCount">0</strong></div>
                    </div>

                    <div style="margin-top:14px">
                        <div id="label-container" class="labels small muted"></div>
                        <div class="waveform" style="margin-top:12px">
                            <canvas id="waveCanvas" width="760" height="200"></canvas>
                        </div>
                        <div class="panel-sub" style="margin-top:12px">
                            <h4 class="small">Live Predictions (this session)</h4>
                            <div id="sessionPredictions" class="session-list small">
                                <p class="muted">No predictions yet in this session.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Video / Emotion Monitoring Panel -->
                <div class="panel" style="margin-top:18px">
                    <div class="panel-header">
                        <h2 style="margin:0">Video Monitoring</h2>
                        <div class="small muted">Emotion recognition for registered faces only</div>
                    </div>

                    <div class="monitor-controls" style="margin-top:12px">
                        <button id="startEmotionMonitorBtn" class="primary">Start Video Monitoring</button>
                        <div id="emotionStatus" class="status" style="margin-left:12px">Status: Camera off</div>
                    </div>

                    <div style="margin-top:14px; display:grid; grid-template-columns: minmax(0, 2fr) minmax(0, 1fr); gap:14px; align-items:flex-start;">
                        <div>
                            <video id="emotionVideo" autoplay playsinline style="width:100%; max-width:480px; border-radius:10px; border:1px solid rgba(15,23,32,0.08); background:#000;"></video>
                        </div>
                        <div style="font-size:14px">
                            <div><strong>Current Emotion:</strong> <span id="emotionCurrent">â€”</span></div>
                            <div style="margin-top:6px"><strong>Confidence:</strong> <span id="emotionConfidence">â€”</span></div>
                            <div style="margin-top:10px">
                                <h4 class="small" style="margin:0 0 6px 0">Emotion Breakdown</h4>
                                <div id="emotionBreakdown" class="small muted">No data yet.</div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <aside class="right" aria-label="History">
                <div class="profile-card">
                    <div style="display:flex;justify-content:space-between;align-items:center">
                        <h4 style="margin:0">Detection History</h4>
                        <div class="small muted">Filter: <strong id="historyRecipient">All</strong></div>
                    </div>
                    <div id="recordings-container" class="history-list" style="margin-top:12px;max-height:640px;overflow:auto">
                        <p class="muted">No recordings yet.</p>
                    </div>
                </div>
            </aside>
        </main>
    </div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands"></script>
<script>
// Ensure user is logged in
const token = localStorage.getItem('token');
if (!token) {
    window.location.href = 'index.html';
}

// ADD LOGOUT FUNCTIONALITY AT THE TOP
document.getElementById('logoutBtn').addEventListener('click', function() {
    localStorage.removeItem('token');
    window.location.href = 'index.html';
});

document.getElementById('welcomeMsg').textContent = 'Logged in - audio monitoring ready.';
// Backend API base (ensure this matches where your FastAPI app runs)
const API_BASE = 'http://127.0.0.1:8000';
// Session-scoped predictions (in-memory for this login session)
let sessionPredictions = [];
let selectedRecipientId = null;
let selectedRecipientName = null;

// On load, fetch profile and server-side recordings for this user
fetchProfile().catch(err => console.warn('Could not fetch profile on load', err));
fetchAndRenderRecordings().catch(err => console.warn('Could not fetch recordings on load', err));

// Wire open-profile button to open a separate window showing profile details
document.getElementById('openProfileBtn').addEventListener('click', () => {
    window.open('profile.html?type=caretaker', '_blank', 'width=420,height=720');
});

// --- Start of merged audio UI (adapted from project root) ---
let audioContext, analyser, dataArray;
let coughLabel = "COUGH";
let coughCount = 0;
let recognitionActive = false;
let audioStream = null;
let processorNode = null;
let silentGainNode = null;
let pcmBuffer = [];
let pcmBufferLength = 0;
const PCM_BUFFER_SECONDS = 6;
const MIN_RECORDING_DURATION = 4000;
let coughDetectionActive = false;
let coughStartTime = null;
let coughRecordingTimeout = null;

const AUTO_DOWNLOAD = false; // set false to avoid saving to user's Downloads
const startBtn = document.getElementById("startBtn");
startBtn.addEventListener("click", toggleRecording);

async function toggleRecording() {
    if (!recognitionActive) {
        await init();
        startBtn.textContent = 'Stop Listening';
        recognitionActive = true;
    } else {
        stopRecording();
        startBtn.textContent = 'Start Listening';
        recognitionActive = false;
    }
}

async function init() {
    // Load model files from backend server where they are mounted at /model
    const MODEL_BASE = API_BASE + '/model';
    const recognizer = speechCommands.create(
        "BROWSER_FFT",
        undefined,
        MODEL_BASE + "/model.json",
        MODEL_BASE + "/metadata.json"
    );

    try {
        await recognizer.ensureModelLoaded();
        document.getElementById('status').textContent = 'Status: Ready - Listening for coughs...';
        const labels = recognizer.wordLabels();
        const container = document.getElementById("label-container");
        container.innerHTML = "";
        labels.forEach(() => container.appendChild(document.createElement("div")));

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        audioStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true, sampleRate: 44100 } });
        const source = audioContext.createMediaStreamSource(audioStream);
        startContinuousRecording(source);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        let bufferLength = analyser.frequencyBinCount;
        dataArray = new Uint8Array(bufferLength);
        source.connect(analyser);
        drawWaveform();

        let coughScoreThreshold = 0.65;

        recognizer.listen(
            result => {
                const scores = result.scores;
                scores.forEach((score, i) => {
                    if (container.childNodes[i]) {
                        container.childNodes[i].textContent = `${labels[i]}: ${score.toFixed(2)}`;
                    }
                });

                const coughIndex = labels.indexOf(coughLabel);
                const coughScore = coughIndex >= 0 ? scores[coughIndex] : 0;
                const statusEl = document.getElementById('status');
                if (!coughDetectionActive) {
                    statusEl.innerHTML = `Listening... (Cough: ${coughScore.toFixed(2)})`;
                    statusEl.style.color = '#2563eb';
                }

                if (coughScore >= coughScoreThreshold) {
                    // record session-scoped prediction immediately
                    addSessionPrediction({ score: coughScore, timestamp: Date.now(), recipient_id: selectedRecipientId, recipient_name: selectedRecipientName });

                    if (!coughDetectionActive) {
                        coughDetectionActive = true;
                        coughStartTime = Date.now();
                        coughCount++;
                        document.getElementById('coughCount').textContent = coughCount;
                        statusEl.textContent = `ðŸš¨ Cough #${coughCount} detected! (${coughScore.toFixed(2)}) - Recording...`;
                        statusEl.style.color = '#ef4444';
                        if (coughRecordingTimeout) clearTimeout(coughRecordingTimeout);
                        coughRecordingTimeout = setTimeout(() => { saveCoughRecording(coughScore); }, MIN_RECORDING_DURATION);
                    } else {
                        const elapsedTime = Date.now() - coughStartTime;
                        if (elapsedTime < MIN_RECORDING_DURATION) {
                            if (coughRecordingTimeout) clearTimeout(coughRecordingTimeout);
                            coughRecordingTimeout = setTimeout(() => { saveCoughRecording(coughScore); }, MIN_RECORDING_DURATION - elapsedTime);
                        }
                    }
                }
            },
            { includeSpectrogram: true, overlapFactor: 0.5, invokeCallbackOnNoiseAndUnknown: true, probabilityThreshold: 0.5 }
        );
        document.getElementById('status').textContent = 'Listening for coughs...';
    } catch (err) {
        console.error('Error init audio:', err);
        document.getElementById('status').textContent = `Error: ${err.message}`;
        document.getElementById('status').style.color = '#ef4444';
    }
}

function startContinuousRecording(source) {
    pcmBuffer = [];
    pcmBufferLength = 0;
    const bufferSize = 4096;
    const channelCount = source.channelCount || 1;
    const maxSamples = audioContext.sampleRate * PCM_BUFFER_SECONDS;

    // ScriptProcessorNode used for now; consider migrating to AudioWorklet
    processorNode = audioContext.createScriptProcessor(bufferSize, channelCount, channelCount);
    processorNode.onaudioprocess = (event) => {
        const inputBuffer = event.inputBuffer;
        const chunkChannels = [];
        for (let ch = 0; ch < inputBuffer.numberOfChannels; ch++) {
            const channelData = new Float32Array(inputBuffer.length);
            channelData.set(inputBuffer.getChannelData(ch));
            chunkChannels.push(channelData);
        }
        pcmBuffer.push({ channels: chunkChannels, length: inputBuffer.length });
        pcmBufferLength += inputBuffer.length;

        while (pcmBufferLength > maxSamples && pcmBuffer.length > 0) {
            const removed = pcmBuffer.shift();
            pcmBufferLength -= removed.length;
        }
    };

    silentGainNode = audioContext.createGain();
    silentGainNode.gain.value = 0;
    source.connect(processorNode);
    processorNode.connect(silentGainNode);
    silentGainNode.connect(audioContext.destination);
}

async function saveCoughRecording(detectedScore) {
    if (!coughDetectionActive) return;
    if (pcmBuffer.length === 0) { coughDetectionActive = false; return; }

    const numChannels = pcmBuffer[0].channels.length;
    const totalSamples = pcmBufferLength;
    const sampleRate = audioContext.sampleRate;
    const channelData = Array.from({ length: numChannels }, () => new Float32Array(totalSamples));
    let offset = 0;
    pcmBuffer.forEach(chunk => {
        for (let ch = 0; ch < numChannels; ch++) {
            channelData[ch].set(chunk.channels[ch], offset);
        }
        offset += chunk.length;
    });

    const audioBufferOut = audioContext.createBuffer(numChannels, totalSamples, sampleRate);
    for (let ch = 0; ch < numChannels; ch++) {
        audioBufferOut.getChannelData(ch).set(channelData[ch]);
    }

    const wavData = encodeWAV(audioBufferOut);
    const wavBlob = new Blob([wavData], { type: 'audio/wav' });
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `cough_${coughCount}_${timestamp}.wav`;
    const downloadUrl = URL.createObjectURL(wavBlob);
    if (AUTO_DOWNLOAD) {
        triggerDownload(downloadUrl, filename);
    }
    showRecording(filename, downloadUrl, 'audio/wav');

    // Upload to backend including selected recipient id (if any)
    try {
        const serverRec = await uploadRecording(wavBlob, filename, selectedRecipientId);
        if (serverRec && serverRec.recording && serverRec.recording.id) {
            await fetchAndRenderRecordings();
        }
    } catch (err) {
        console.error('Upload failed', err);
    }

    coughDetectionActive = false;
    coughStartTime = null;
    const statusEl = document.getElementById('status');
    statusEl.textContent = 'Listening for coughs...';
    statusEl.style.color = '#2563eb';
}

function showRecording(filename, url, mimeType = 'audio/wav') {
    const container = document.getElementById('recordings-container');
    const title = document.getElementById('recordings-title');
    if (container.children.length === 0) { title.style.display = 'block'; }
    const div = document.createElement('div');
    div.style.marginBottom = '10px';
    div.innerHTML = `
        <a href="${url}" download="${filename}">ðŸ“¥ ${filename}</a>
        <audio controls style="margin-left: 10px; vertical-align: middle;" preload="none">
            <source src="${url}" type="${mimeType}">
        </audio>
    `;
    container.insertBefore(div, container.firstChild);
}

function triggerDownload(url, filename) {
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    setTimeout(() => { if (a.parentNode) a.parentNode.removeChild(a); }, 0);
}

function encodeWAV(audioBuffer) {
    const numChannels = audioBuffer.numberOfChannels;
    const sampleRate = audioBuffer.sampleRate;
    const bitDepth = 16;
    const bytesPerSample = bitDepth / 8;
    const numFrames = audioBuffer.length;
    const dataSize = numFrames * numChannels * bytesPerSample;
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);
    function writeString(view, offset, string) { for (let i = 0; i < string.length; i++) view.setUint8(offset + i, string.charCodeAt(i)); }
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * bytesPerSample, true);
    view.setUint16(32, numChannels * bytesPerSample, true);
    view.setUint16(34, bitDepth, true);
    writeString(view, 36, 'data');
    view.setUint32(40, dataSize, true);
    let offset = 44;
    for (let frame = 0; frame < numFrames; frame++) {
        for (let channel = 0; channel < numChannels; channel++) {
            let sample = audioBuffer.getChannelData(channel)[frame];
            sample = Math.max(-1, Math.min(1, sample));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }
    }
    return buffer;
}

function stopRecording() {
    if (processorNode) { processorNode.disconnect(); processorNode.onaudioprocess = null; processorNode = null; }
    if (silentGainNode) { silentGainNode.disconnect(); silentGainNode = null; }
    if (coughRecordingTimeout) clearTimeout(coughRecordingTimeout);
    if (audioStream) audioStream.getTracks().forEach(track => track.stop());
    if (audioContext && audioContext.state !== 'closed') audioContext.close();
    pcmBuffer = []; pcmBufferLength = 0; coughDetectionActive = false;
    document.getElementById('status').textContent = 'Stopped';
    document.getElementById('status').style.color = '#ef4444';
}

// Add a prediction to the session list and re-render
function addSessionPrediction(pred) {
    sessionPredictions.unshift(pred);
    // keep only recent 200 predictions in memory
    if (sessionPredictions.length > 200) sessionPredictions.pop();
    renderSessionPredictions();
}

function renderSessionPredictions() {
    const el = document.getElementById('sessionPredictions');
    el.innerHTML = '';
    if (!sessionPredictions || sessionPredictions.length === 0) {
        el.innerHTML = '<p class="muted">No predictions yet in this session.</p>';
        return;
    }
    sessionPredictions.slice(0, 50).forEach(p => {
        const d = document.createElement('div');
        d.style.padding = '6px 8px';
        d.style.borderBottom = '1px dashed rgba(0,0,0,0.04)';
        const time = new Date(p.timestamp).toLocaleTimeString();
        d.innerHTML = `<strong style="color:#0f1720">${(p.score||0).toFixed(2)}</strong> â€” <span class="muted">${time}</span> ${p.recipient_name ? 'â€¢ ' + p.recipient_name : ''}`;
        el.appendChild(d);
    });
}

// Fetch caretaker profile and render recipients
async function fetchProfile() {
    try {
        const res = await fetch(API_BASE + '/profile', {
            method: 'GET',
            headers: { 'Authorization': 'Bearer ' + token }
        });
        if (!res.ok) {
            console.error('Failed to fetch profile', res.status);
            return;
        }
        const data = await res.json();
        if (!data || !data.caretaker) return;

        const c = data.caretaker;
        const nameEl = document.getElementById('caretakerName');
        const emailEl = document.getElementById('caretakerEmail');
        if (nameEl) nameEl.textContent = c.full_name || c.username;
        if (emailEl) emailEl.textContent = c.email || '';

        const list = document.getElementById('recipientsList');
        list.innerHTML = '';
        if (!data.care_recipients || data.care_recipients.length === 0) {
            list.innerHTML = '<p class="muted">No recipients added.</p>';
            return;
        }

        // Add 'All' option
        const allCard = document.createElement('div');
        allCard.className = 'recipient-card';
        allCard.textContent = 'All recipients';
        allCard.dataset.recipientId = '';
        allCard.addEventListener('click', () => selectRecipient(null, 'All', allCard));
        list.appendChild(allCard);

        data.care_recipients.forEach(r => {
            const card = document.createElement('div');
            card.className = 'recipient-card';
            card.dataset.recipientId = r.id;
            const meta = `Age: ${r.age || '-'} â€¢ ${r.gender || '-'} â€¢ ${r.respiratory_condition_status ? 'Respiratory' : 'No condition'}`;
            const innerLeft = document.createElement('div');
            innerLeft.style.flex = '1';
            const nameEl = document.createElement('div'); nameEl.className = 'recipient-name'; nameEl.textContent = r.full_name;
            const metaEl = document.createElement('div'); metaEl.className = 'recipient-meta'; metaEl.textContent = meta;
            innerLeft.appendChild(nameEl); innerLeft.appendChild(metaEl);

            const actions = document.createElement('div'); actions.className = 'recipient-actions';
            const selectBtn = document.createElement('button'); selectBtn.textContent = 'Select';
            selectBtn.addEventListener('click', (ev) => { ev.stopPropagation(); selectRecipient(r.id, r.full_name, card); });
            const viewBtn = document.createElement('button'); viewBtn.textContent = 'View';
            viewBtn.addEventListener('click', (ev) => { ev.stopPropagation(); window.open(`profile.html?recipient_id=${r.id}`, '_blank', 'width=420,height=720'); });
            actions.appendChild(selectBtn); actions.appendChild(viewBtn);

            card.appendChild(innerLeft); card.appendChild(actions);
            // clicking the whole card also selects
            card.addEventListener('click', () => selectRecipient(r.id, r.full_name, card));
            list.appendChild(card);
        });

    } catch (err) {
        console.error('Error fetching profile', err);
    }
}

function selectRecipient(id, name, cardEl = null) {
    selectedRecipientId = id;
    selectedRecipientName = name || null;
    document.getElementById('selectedRecipient').textContent = selectedRecipientName || 'All';
    document.getElementById('historyRecipient').textContent = selectedRecipientName || 'All';
    // highlight active card
    document.querySelectorAll('.recipient-card').forEach(c => c.classList.remove('active'));
    if (cardEl) cardEl.classList.add('active');
    // refresh server-side recordings filtered by recipient
    fetchAndRenderRecordings();
}

function drawWaveform() {
    requestAnimationFrame(drawWaveform);
    const canvas = document.getElementById("waveCanvas");
    const ctx = canvas.getContext("2d");
    if (!analyser) return;
    analyser.getByteTimeDomainData(dataArray);
    ctx.fillStyle = "rgba(255,255,255,0.9)";
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    drawGrid(ctx, canvas);
    ctx.lineWidth = 2;
    ctx.strokeStyle = "#7cc4d6";
    ctx.beginPath();
    const sliceWidth = canvas.width * 1.0 / analyser.frequencyBinCount;
    let x = 0;
    for (let i = 0; i < analyser.frequencyBinCount; i++) {
        const v = dataArray[i] / 128.0;
        const y = v * canvas.height / 2;
        if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
        x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();
}

function drawGrid(ctx, canvas) {
    ctx.strokeStyle = "rgba(15,23,32,0.03)";
    ctx.lineWidth = 1;
    for (let i = 1; i < 6; i++) {
        let y = (canvas.height / 6) * i;
        ctx.beginPath(); ctx.moveTo(0, y); ctx.lineTo(canvas.width, y); ctx.stroke();
    }
}

async function uploadRecording(blob, filename, care_recipient_id = null) {
    const form = new FormData();
    const file = new File([blob], filename, { type: 'audio/wav' });
    form.append('file', file);
    if (care_recipient_id) form.append('care_recipient_id', care_recipient_id);
    const res = await fetch(API_BASE + '/recordings/upload', {
        method: 'POST',
        headers: { 'Authorization': 'Bearer ' + token },
        body: form
    });
    if (!res.ok) {
        const body = await res.text();
        console.error('Upload failed', res.status, body);
        return null;
    }
    const data = await res.json();
    console.log('Uploaded recording:', data);
    return data;
}

// Fetch and render the authenticated user's server-side recordings
async function fetchAndRenderRecordings() {
    const container = document.getElementById('recordings-container');
    container.innerHTML = '';
    try {
        let url = API_BASE + '/recordings/my';
        if (selectedRecipientId) url += '?care_recipient_id=' + encodeURIComponent(selectedRecipientId);
        const res = await fetch(url, {
            method: 'GET',
            headers: { 'Authorization': 'Bearer ' + token }
        });
        if (!res.ok) {
            console.error('Failed to list recordings', res.status);
            return;
        }
        const data = await res.json();
        if (!data.recordings || data.recordings.length === 0) {
            container.innerHTML = '<p class="muted">No recordings yet.</p>';
            return;
        }
        for (const r of data.recordings) {
            const div = document.createElement('div');
            div.style.marginBottom = '10px';
            const title = document.createElement('div');
            title.innerHTML = `<strong>${r.filename}</strong><div class="muted small">${new Date(r.created_at).toLocaleString()} ${r.care_recipient_id ? 'â€¢ Recipient: ' + r.care_recipient_id : ''}</div>`;

            const playBtn = document.createElement('button');
            playBtn.textContent = 'Play';
            playBtn.style.marginRight = '8px';
            playBtn.addEventListener('click', () => playRecording(r.id));

            const dlBtn = document.createElement('button');
            dlBtn.textContent = 'Download';
            dlBtn.addEventListener('click', () => downloadRecording(r.id, r.filename));

            div.appendChild(title);
            div.appendChild(playBtn);
            div.appendChild(dlBtn);
            container.appendChild(div);
        }
    } catch (err) {
        console.error('Error fetching recordings', err);
    }
}

// Fetch recorded audio bytes with Authorization header and play in a temporary audio element
async function playRecording(id) {
    try {
        const res = await fetch(`${API_BASE}/recordings/${id}/download`, {
            method: 'GET',
            headers: { 'Authorization': 'Bearer ' + token }
        });
        if (!res.ok) {
            console.error('Failed to fetch recording', res.status);
            return;
        }
        const blob = await res.blob();
        const url = URL.createObjectURL(blob);
        const audio = document.createElement('audio');
        audio.src = url;
        audio.controls = true;
        audio.autoplay = true;
        const container = document.getElementById('recordings-container');
        const wrapper = document.createElement('div');
        wrapper.style.marginBottom = '10px';
        wrapper.appendChild(audio);
        container.insertBefore(wrapper, container.firstChild);
    } catch (err) {
        console.error('Error playing recording', err);
    }
}

// Authenticated download (fetch with Authorization header and trigger download)
async function downloadRecording(id, filename) {
    try {
        const res = await fetch(`${API_BASE}/recordings/${id}/download`, {
            method: 'GET',
            headers: { 'Authorization': 'Bearer ' + token }
        });
        if (!res.ok) {
            console.error('Failed to fetch recording for download', res.status);
            return;
        }
        const blob = await res.blob();
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = filename || `recording_${id}.wav`;
        document.body.appendChild(a);
        a.click();
        a.remove();
        setTimeout(() => URL.revokeObjectURL(url), 5000);
    } catch (err) {
        console.error('Error downloading recording', err);
    }
}

// ==============================
// Video / Emotion Monitoring UI
// ==============================
const EMOTION_API_BASE = 'http://127.0.0.1:5000'; // Flask emotion service
const startEmotionBtn = document.getElementById('startEmotionMonitorBtn');
const emotionVideo = document.getElementById('emotionVideo');
const emotionStatus = document.getElementById('emotionStatus');
const emotionCurrentEl = document.getElementById('emotionCurrent');
const emotionConfEl = document.getElementById('emotionConfidence');
const emotionBreakdownEl = document.getElementById('emotionBreakdown');

let emotionStream = null;
let emotionCaptureInterval = null;
let emotionMonitoringActive = false;

startEmotionBtn.addEventListener('click', toggleEmotionMonitoring);

async function toggleEmotionMonitoring() {
    if (!emotionMonitoringActive) {
        await startEmotionMonitoring();
    } else {
        stopEmotionMonitoring();
    }
}

async function startEmotionMonitoring() {
    try {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            emotionStatus.textContent = 'Status: Camera not supported in this browser';
            emotionStatus.style.color = '#ef4444';
            return;
        }

        emotionStatus.textContent = 'Status: Requesting camera...';
        emotionStatus.style.color = '#2563eb';

        emotionStream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
        emotionVideo.srcObject = emotionStream;

        emotionMonitoringActive = true;
        startEmotionBtn.textContent = 'Stop Video Monitoring';
        emotionStatus.textContent = 'Status: Camera on - analyzing...';
        emotionStatus.style.color = '#2563eb';

        // Capture a frame every 2 seconds
        if (emotionCaptureInterval) clearInterval(emotionCaptureInterval);
        emotionCaptureInterval = setInterval(captureAndSendEmotionFrame, 2000);
    } catch (err) {
        console.error('Error starting emotion monitoring:', err);
        emotionStatus.textContent = 'Status: Failed to access camera';
        emotionStatus.style.color = '#ef4444';
    }
}

function stopEmotionMonitoring() {
    emotionMonitoringActive = false;
    startEmotionBtn.textContent = 'Start Video Monitoring';
    if (emotionCaptureInterval) {
        clearInterval(emotionCaptureInterval);
        emotionCaptureInterval = null;
    }
    if (emotionStream) {
        emotionStream.getTracks().forEach(t => t.stop());
        emotionStream = null;
    }
    emotionVideo.srcObject = null;
    emotionStatus.textContent = 'Status: Camera off';
    emotionStatus.style.color = '#6b7280';
}

async function captureAndSendEmotionFrame() {
    if (!emotionMonitoringActive || !emotionVideo || emotionVideo.readyState < 2) return;

    try {
        // Draw current video frame to an offscreen canvas
        const canvas = document.createElement('canvas');
        canvas.width = emotionVideo.videoWidth || 640;
        canvas.height = emotionVideo.videoHeight || 480;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(emotionVideo, 0, 0, canvas.width, canvas.height);

        const dataUrl = canvas.toDataURL('image/jpeg', 0.8);

        const res = await fetch(EMOTION_API_BASE + '/api/analyze/emotion', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ image: dataUrl })
        });

        if (!res.ok) {
            console.warn('Emotion API error:', res.status);
            return;
        }

        const data = await res.json();

        if (!data || data.user_id === null || data.dominant_emotion === null) {
            // Unknown face / no clear face / not the registered user
            emotionCurrentEl.textContent = 'â€”';
            emotionConfEl.textContent = 'â€”';
            emotionBreakdownEl.textContent = 'No recognized user in frame.';
            return;
        }

        // Update UI with detected emotion
        emotionCurrentEl.textContent = data.dominant_emotion;
        emotionConfEl.textContent = data.confidence != null ? data.confidence.toFixed(1) + '%' : 'â€”';

        if (data.emotions && Object.keys(data.emotions).length > 0) {
            const parts = Object.entries(data.emotions)
                .sort((a, b) => b[1] - a[1])
                .slice(0, 5)
                .map(([k, v]) => `${k}: ${v.toFixed(1)}%`);
            emotionBreakdownEl.textContent = parts.join(' | ');
        } else {
            emotionBreakdownEl.textContent = 'No detailed emotion breakdown.';
        }

    } catch (err) {
        console.error('Error capturing/sending emotion frame:', err);
    }
}

// --- End of audio + video UI ---
</script>
</body>
</html>